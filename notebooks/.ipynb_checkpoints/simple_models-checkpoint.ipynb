{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "from sklearn.externals import joblib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/scaled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>001476ffa</th>\n",
       "      <th>0019109c4</th>\n",
       "      <th>0022de2b3</th>\n",
       "      <th>0024cd760</th>\n",
       "      <th>002d634dc</th>\n",
       "      <th>00302fe51</th>\n",
       "      <th>003da5628</th>\n",
       "      <th>006e72749</th>\n",
       "      <th>007d71f12</th>\n",
       "      <th>007ee91d1</th>\n",
       "      <th>...</th>\n",
       "      <th>ffa6b80e2</th>\n",
       "      <th>ffa903344</th>\n",
       "      <th>ffb34b926</th>\n",
       "      <th>ffca57b7b</th>\n",
       "      <th>ffcec956f</th>\n",
       "      <th>ffd2f9409</th>\n",
       "      <th>ffd50f0bf</th>\n",
       "      <th>ffdc4bcf8</th>\n",
       "      <th>ffec49dae</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.056086</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.025481</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.041888</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.052255</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071927</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.058426</td>\n",
       "      <td>-0.03197</td>\n",
       "      <td>17.453097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.056086</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.025481</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.041888</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.052255</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071927</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.058426</td>\n",
       "      <td>-0.03197</td>\n",
       "      <td>13.304687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.056086</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.025481</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.041888</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.052255</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071927</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.058426</td>\n",
       "      <td>-0.03197</td>\n",
       "      <td>16.118096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.056086</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.025481</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.041888</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.052255</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071927</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.058426</td>\n",
       "      <td>-0.03197</td>\n",
       "      <td>14.508658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056086</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.025481</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.041888</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.052255</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071927</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.058426</td>\n",
       "      <td>-0.03197</td>\n",
       "      <td>16.482739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   001476ffa  0019109c4  0022de2b3  0024cd760  002d634dc  00302fe51  \\\n",
       "0  -0.056086  -0.032696  -0.025481  -0.048058  -0.041888  -0.036611   \n",
       "1  -0.056086  -0.032696  -0.025481  -0.048058  -0.041888  -0.036611   \n",
       "2  -0.056086  -0.032696  -0.025481  -0.048058  -0.041888  -0.036611   \n",
       "3  -0.056086  -0.032696  -0.025481  -0.048058  -0.041888  -0.036611   \n",
       "4  -0.056086  -0.032696  -0.025481  -0.048058  -0.041888  -0.036611   \n",
       "\n",
       "   003da5628  006e72749  007d71f12  007ee91d1    ...      ffa6b80e2  \\\n",
       "0  -0.052255  -0.025899  -0.029453  -0.032681    ...      -0.071927   \n",
       "1  -0.052255  -0.025899  -0.029453  -0.032681    ...      -0.071927   \n",
       "2  -0.052255  -0.025899  -0.029453  -0.032681    ...      -0.071927   \n",
       "3  -0.052255  -0.025899  -0.029453  -0.032681    ...      -0.071927   \n",
       "4  -0.052255  -0.025899  -0.029453  -0.032681    ...      -0.071927   \n",
       "\n",
       "   ffa903344  ffb34b926  ffca57b7b  ffcec956f  ffd2f9409  ffd50f0bf  \\\n",
       "0  -0.036566  -0.054832  -0.031014  -0.052007  -0.033871  -0.023249   \n",
       "1  -0.036566  -0.054832  -0.031014  -0.052007  -0.033871  -0.023249   \n",
       "2  -0.036566  -0.054832  -0.031014  -0.052007  -0.033871  -0.023249   \n",
       "3  -0.036566  -0.054832  -0.031014  -0.052007  -0.033871  -0.023249   \n",
       "4  -0.036566  -0.054832  -0.031014  -0.052007  -0.033871  -0.023249   \n",
       "\n",
       "   ffdc4bcf8  ffec49dae     target  \n",
       "0  -0.058426   -0.03197  17.453097  \n",
       "1  -0.058426   -0.03197  13.304687  \n",
       "2  -0.058426   -0.03197  16.118096  \n",
       "3  -0.058426   -0.03197  14.508658  \n",
       "4  -0.058426   -0.03197  16.482739  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, pred):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(pred), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, pred):\n",
    "    return np.sqrt((1/len(y))*np.sum((np.log1p(pred)-np.log1p(y))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1992\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = RANDOM_STATE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(train.drop(['target','ID'], axis = 1))\n",
    "y = np.array(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 1\n",
      "score = 0.09788592929548452\n",
      "fold = 2\n",
      "score = 0.10030396577452731\n",
      "fold = 3\n",
      "score = 0.09887804164588578\n",
      "fold = 4\n",
      "score = 0.100765523750447\n",
      "fold = 5\n",
      "score = 0.10264823706886024\n",
      "mean score: 0.1\n"
     ]
    }
   ],
   "source": [
    "scores_list = list()\n",
    "n = 1\n",
    "model = RandomForestRegressor(n_jobs = 4, random_state = RANDOM_STATE)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold = {}'.format(n))\n",
    "    train_X, valid_X = X[train_index], X[test_index]\n",
    "    train_y, valid_y = y[train_index], y[test_index]\n",
    "    model.fit(train_X, train_y)\n",
    "    preds = model.predict(valid_X)\n",
    "    score = rmsle(valid_y, preds)\n",
    "    print('score = {}'.format(score))\n",
    "    scores_list.append(score)\n",
    "    n += 1\n",
    "    \n",
    "print('mean score: {}'.format(round(np.sum(scores_list)/K,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 1\n",
      "score = 0.10994352349998218\n",
      "fold = 2\n",
      "score = 0.11106330952404397\n",
      "fold = 3\n",
      "score = 0.11234453415257518\n",
      "fold = 4\n",
      "score = 0.11378890492461681\n",
      "fold = 5\n",
      "score = 0.11513434322790428\n",
      "mean score: 0.11\n"
     ]
    }
   ],
   "source": [
    "scores_list = list()\n",
    "n = 1\n",
    "model = Lasso(alpha = 0.1, random_state = RANDOM_STATE)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold = {}'.format(n))\n",
    "    train_X, valid_X = X[train_index], X[test_index]\n",
    "    train_y, valid_y = y[train_index], y[test_index]\n",
    "    model.fit(train_X, train_y)\n",
    "    preds = model.predict(valid_X)\n",
    "    score = rmsle(valid_y, preds)\n",
    "    print('score = {}'.format(score))\n",
    "    scores_list.append(score)\n",
    "    n += 1\n",
    "    \n",
    "print('mean score: {}'.format(round(np.sum(scores_list)/K,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 1\n",
      "[1]\tvalid_0's l2: 2.91608\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.85412\n",
      "[3]\tvalid_0's l2: 2.79997\n",
      "[4]\tvalid_0's l2: 2.7513\n",
      "[5]\tvalid_0's l2: 2.70179\n",
      "[6]\tvalid_0's l2: 2.65037\n",
      "[7]\tvalid_0's l2: 2.60244\n",
      "[8]\tvalid_0's l2: 2.55809\n",
      "[9]\tvalid_0's l2: 2.52562\n",
      "[10]\tvalid_0's l2: 2.49254\n",
      "[11]\tvalid_0's l2: 2.46059\n",
      "[12]\tvalid_0's l2: 2.43038\n",
      "[13]\tvalid_0's l2: 2.4065\n",
      "[14]\tvalid_0's l2: 2.38424\n",
      "[15]\tvalid_0's l2: 2.36019\n",
      "[16]\tvalid_0's l2: 2.33787\n",
      "[17]\tvalid_0's l2: 2.3136\n",
      "[18]\tvalid_0's l2: 2.2929\n",
      "[19]\tvalid_0's l2: 2.27866\n",
      "[20]\tvalid_0's l2: 2.26342\n",
      "[21]\tvalid_0's l2: 2.25248\n",
      "[22]\tvalid_0's l2: 2.23858\n",
      "[23]\tvalid_0's l2: 2.22664\n",
      "[24]\tvalid_0's l2: 2.21709\n",
      "[25]\tvalid_0's l2: 2.20629\n",
      "[26]\tvalid_0's l2: 2.19334\n",
      "[27]\tvalid_0's l2: 2.18456\n",
      "[28]\tvalid_0's l2: 2.17564\n",
      "[29]\tvalid_0's l2: 2.16557\n",
      "[30]\tvalid_0's l2: 2.15261\n",
      "score = 0.09796925495911162\n",
      "fold = 2\n",
      "[1]\tvalid_0's l2: 2.95948\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.90952\n",
      "[3]\tvalid_0's l2: 2.86578\n",
      "[4]\tvalid_0's l2: 2.82397\n",
      "[5]\tvalid_0's l2: 2.78316\n",
      "[6]\tvalid_0's l2: 2.73389\n",
      "[7]\tvalid_0's l2: 2.69775\n",
      "[8]\tvalid_0's l2: 2.66339\n",
      "[9]\tvalid_0's l2: 2.62188\n",
      "[10]\tvalid_0's l2: 2.59217\n",
      "[11]\tvalid_0's l2: 2.5561\n",
      "[12]\tvalid_0's l2: 2.52496\n",
      "[13]\tvalid_0's l2: 2.4989\n",
      "[14]\tvalid_0's l2: 2.47348\n",
      "[15]\tvalid_0's l2: 2.45449\n",
      "[16]\tvalid_0's l2: 2.43064\n",
      "[17]\tvalid_0's l2: 2.40759\n",
      "[18]\tvalid_0's l2: 2.3921\n",
      "[19]\tvalid_0's l2: 2.3766\n",
      "[20]\tvalid_0's l2: 2.3629\n",
      "[21]\tvalid_0's l2: 2.3473\n",
      "[22]\tvalid_0's l2: 2.32984\n",
      "[23]\tvalid_0's l2: 2.31402\n",
      "[24]\tvalid_0's l2: 2.29716\n",
      "[25]\tvalid_0's l2: 2.28098\n",
      "[26]\tvalid_0's l2: 2.2684\n",
      "[27]\tvalid_0's l2: 2.26045\n",
      "[28]\tvalid_0's l2: 2.24861\n",
      "[29]\tvalid_0's l2: 2.24306\n",
      "[30]\tvalid_0's l2: 2.23543\n",
      "score = 0.10034579161237163\n",
      "fold = 3\n",
      "[1]\tvalid_0's l2: 2.87095\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.81593\n",
      "[3]\tvalid_0's l2: 2.76166\n",
      "[4]\tvalid_0's l2: 2.71629\n",
      "[5]\tvalid_0's l2: 2.67201\n",
      "[6]\tvalid_0's l2: 2.63279\n",
      "[7]\tvalid_0's l2: 2.5954\n",
      "[8]\tvalid_0's l2: 2.56321\n",
      "[9]\tvalid_0's l2: 2.5233\n",
      "[10]\tvalid_0's l2: 2.48708\n",
      "[11]\tvalid_0's l2: 2.46275\n",
      "[12]\tvalid_0's l2: 2.43743\n",
      "[13]\tvalid_0's l2: 2.41322\n",
      "[14]\tvalid_0's l2: 2.38992\n",
      "[15]\tvalid_0's l2: 2.37058\n",
      "[16]\tvalid_0's l2: 2.34729\n",
      "[17]\tvalid_0's l2: 2.32335\n",
      "[18]\tvalid_0's l2: 2.30347\n",
      "[19]\tvalid_0's l2: 2.28813\n",
      "[20]\tvalid_0's l2: 2.2722\n",
      "[21]\tvalid_0's l2: 2.2547\n",
      "[22]\tvalid_0's l2: 2.24057\n",
      "[23]\tvalid_0's l2: 2.22825\n",
      "[24]\tvalid_0's l2: 2.21191\n",
      "[25]\tvalid_0's l2: 2.19852\n",
      "[26]\tvalid_0's l2: 2.19304\n",
      "[27]\tvalid_0's l2: 2.18343\n",
      "[28]\tvalid_0's l2: 2.17414\n",
      "[29]\tvalid_0's l2: 2.16821\n",
      "[30]\tvalid_0's l2: 2.16202\n",
      "score = 0.09923619840937313\n",
      "fold = 4\n",
      "[1]\tvalid_0's l2: 3.10912\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 3.04793\n",
      "[3]\tvalid_0's l2: 2.99223\n",
      "[4]\tvalid_0's l2: 2.93046\n",
      "[5]\tvalid_0's l2: 2.87492\n",
      "[6]\tvalid_0's l2: 2.81617\n",
      "[7]\tvalid_0's l2: 2.76956\n",
      "[8]\tvalid_0's l2: 2.7279\n",
      "[9]\tvalid_0's l2: 2.68836\n",
      "[10]\tvalid_0's l2: 2.65182\n",
      "[11]\tvalid_0's l2: 2.61486\n",
      "[12]\tvalid_0's l2: 2.57851\n",
      "[13]\tvalid_0's l2: 2.54058\n",
      "[14]\tvalid_0's l2: 2.51151\n",
      "[15]\tvalid_0's l2: 2.48569\n",
      "[16]\tvalid_0's l2: 2.45616\n",
      "[17]\tvalid_0's l2: 2.42707\n",
      "[18]\tvalid_0's l2: 2.39945\n",
      "[19]\tvalid_0's l2: 2.37878\n",
      "[20]\tvalid_0's l2: 2.36452\n",
      "[21]\tvalid_0's l2: 2.34534\n",
      "[22]\tvalid_0's l2: 2.32864\n",
      "[23]\tvalid_0's l2: 2.31207\n",
      "[24]\tvalid_0's l2: 2.29401\n",
      "[25]\tvalid_0's l2: 2.28259\n",
      "[26]\tvalid_0's l2: 2.27371\n",
      "[27]\tvalid_0's l2: 2.26133\n",
      "[28]\tvalid_0's l2: 2.25295\n",
      "[29]\tvalid_0's l2: 2.2415\n",
      "[30]\tvalid_0's l2: 2.23124\n",
      "score = 0.09988271202373337\n",
      "fold = 5\n",
      "[1]\tvalid_0's l2: 3.15827\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 3.09292\n",
      "[3]\tvalid_0's l2: 3.02887\n",
      "[4]\tvalid_0's l2: 2.97938\n",
      "[5]\tvalid_0's l2: 2.93034\n",
      "[6]\tvalid_0's l2: 2.88515\n",
      "[7]\tvalid_0's l2: 2.84527\n",
      "[8]\tvalid_0's l2: 2.81036\n",
      "[9]\tvalid_0's l2: 2.77131\n",
      "[10]\tvalid_0's l2: 2.74039\n",
      "[11]\tvalid_0's l2: 2.71319\n",
      "[12]\tvalid_0's l2: 2.68406\n",
      "[13]\tvalid_0's l2: 2.65513\n",
      "[14]\tvalid_0's l2: 2.63148\n",
      "[15]\tvalid_0's l2: 2.60686\n",
      "[16]\tvalid_0's l2: 2.57744\n",
      "[17]\tvalid_0's l2: 2.56355\n",
      "[18]\tvalid_0's l2: 2.54672\n",
      "[19]\tvalid_0's l2: 2.52479\n",
      "[20]\tvalid_0's l2: 2.50883\n",
      "[21]\tvalid_0's l2: 2.49503\n",
      "[22]\tvalid_0's l2: 2.48129\n",
      "[23]\tvalid_0's l2: 2.45752\n",
      "[24]\tvalid_0's l2: 2.4455\n",
      "[25]\tvalid_0's l2: 2.42647\n",
      "[26]\tvalid_0's l2: 2.41664\n",
      "[27]\tvalid_0's l2: 2.40565\n",
      "[28]\tvalid_0's l2: 2.3965\n",
      "[29]\tvalid_0's l2: 2.39014\n",
      "[30]\tvalid_0's l2: 2.3783\n",
      "score = 0.10397896223821275\n",
      "mean score: 0.1\n"
     ]
    }
   ],
   "source": [
    "scores_list = list()\n",
    "n = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold = {}'.format(n))\n",
    "    train_X, valid_X = X[train_index], X[test_index]\n",
    "    train_y, valid_y = y[train_index], y[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(valid_X, valid_y, reference=lgb_train)\n",
    "    params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=30,\n",
    "                    valid_sets=lgb_eval,\n",
    "    early_stopping_rounds=10)\n",
    "    \n",
    "    preds = gbm .predict(valid_X)\n",
    "    score = rmsle(valid_y, preds)\n",
    "    print('score = {}'.format(score))\n",
    "    scores_list.append(score)\n",
    "    n += 1\n",
    "    \n",
    "print('mean score: {}'.format(round(np.sum(scores_list)/K,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 1\n",
      "score = 0.09687677946432283\n",
      "fold = 2\n",
      "score = 0.09897650411169517\n",
      "fold = 3\n",
      "score = 0.09904497864816228\n",
      "fold = 4\n",
      "score = 0.09912257986387968\n",
      "fold = 5\n",
      "score = 0.10079244732605544\n",
      "mean score: 0.1\n"
     ]
    }
   ],
   "source": [
    "scores_list = list()\n",
    "n = 1\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold = {}'.format(n))\n",
    "    train_X, valid_X = X[train_index], X[test_index]\n",
    "    train_y, valid_y = y[train_index], y[test_index]\n",
    "    xgb.fit(train_X, train_y)\n",
    "    preds = xgb.predict(valid_X)\n",
    "    score = rmsle(valid_y, preds)\n",
    "    print('score = {}'.format(score))\n",
    "    scores_list.append(score)\n",
    "    n += 1\n",
    "    \n",
    "print('mean score: {}'.format(round(np.sum(scores_list)/K,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 1\n",
      "Training XGBoost model...\n",
      "score XGB = 0.09771178108124753\n",
      "Training LightGBM model...\n",
      "[1]\tvalid_0's l2: 2.91608\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.85412\n",
      "[3]\tvalid_0's l2: 2.79997\n",
      "[4]\tvalid_0's l2: 2.7513\n",
      "[5]\tvalid_0's l2: 2.70179\n",
      "[6]\tvalid_0's l2: 2.65037\n",
      "[7]\tvalid_0's l2: 2.60244\n",
      "[8]\tvalid_0's l2: 2.55809\n",
      "[9]\tvalid_0's l2: 2.52562\n",
      "[10]\tvalid_0's l2: 2.49254\n",
      "[11]\tvalid_0's l2: 2.46059\n",
      "[12]\tvalid_0's l2: 2.43038\n",
      "[13]\tvalid_0's l2: 2.4065\n",
      "[14]\tvalid_0's l2: 2.38424\n",
      "[15]\tvalid_0's l2: 2.36019\n",
      "[16]\tvalid_0's l2: 2.33787\n",
      "[17]\tvalid_0's l2: 2.3136\n",
      "[18]\tvalid_0's l2: 2.2929\n",
      "[19]\tvalid_0's l2: 2.27866\n",
      "[20]\tvalid_0's l2: 2.26342\n",
      "[21]\tvalid_0's l2: 2.25248\n",
      "[22]\tvalid_0's l2: 2.23858\n",
      "[23]\tvalid_0's l2: 2.22664\n",
      "[24]\tvalid_0's l2: 2.21709\n",
      "[25]\tvalid_0's l2: 2.20629\n",
      "[26]\tvalid_0's l2: 2.19334\n",
      "[27]\tvalid_0's l2: 2.18456\n",
      "[28]\tvalid_0's l2: 2.17564\n",
      "[29]\tvalid_0's l2: 2.16557\n",
      "[30]\tvalid_0's l2: 2.15261\n",
      "score LGB = 0.09796925495911162\n",
      "Training Lasso model...\n",
      "score Lasso = 0.10994352349998218\n",
      "Training RandomForest model...\n",
      "score RF = 0.09788592929548452\n",
      "fold = 2\n",
      "Training XGBoost model...\n",
      "score XGB = 0.09948545415961509\n",
      "Training LightGBM model...\n",
      "[1]\tvalid_0's l2: 2.95948\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.90952\n",
      "[3]\tvalid_0's l2: 2.86578\n",
      "[4]\tvalid_0's l2: 2.82397\n",
      "[5]\tvalid_0's l2: 2.78316\n",
      "[6]\tvalid_0's l2: 2.73389\n",
      "[7]\tvalid_0's l2: 2.69775\n",
      "[8]\tvalid_0's l2: 2.66339\n",
      "[9]\tvalid_0's l2: 2.62188\n",
      "[10]\tvalid_0's l2: 2.59217\n",
      "[11]\tvalid_0's l2: 2.5561\n",
      "[12]\tvalid_0's l2: 2.52496\n",
      "[13]\tvalid_0's l2: 2.4989\n",
      "[14]\tvalid_0's l2: 2.47348\n",
      "[15]\tvalid_0's l2: 2.45449\n",
      "[16]\tvalid_0's l2: 2.43064\n",
      "[17]\tvalid_0's l2: 2.40759\n",
      "[18]\tvalid_0's l2: 2.3921\n",
      "[19]\tvalid_0's l2: 2.3766\n",
      "[20]\tvalid_0's l2: 2.3629\n",
      "[21]\tvalid_0's l2: 2.3473\n",
      "[22]\tvalid_0's l2: 2.32984\n",
      "[23]\tvalid_0's l2: 2.31402\n",
      "[24]\tvalid_0's l2: 2.29716\n",
      "[25]\tvalid_0's l2: 2.28098\n",
      "[26]\tvalid_0's l2: 2.2684\n",
      "[27]\tvalid_0's l2: 2.26045\n",
      "[28]\tvalid_0's l2: 2.24861\n",
      "[29]\tvalid_0's l2: 2.24306\n",
      "[30]\tvalid_0's l2: 2.23543\n",
      "score LGB = 0.10034579161237163\n",
      "Training Lasso model...\n",
      "score Lasso = 0.11106330952404397\n",
      "Training RandomForest model...\n",
      "score RF = 0.10030396577452731\n",
      "fold = 3\n",
      "Training XGBoost model...\n",
      "score XGB = 0.09851110458309674\n",
      "Training LightGBM model...\n",
      "[1]\tvalid_0's l2: 2.87095\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 2.81593\n",
      "[3]\tvalid_0's l2: 2.76166\n",
      "[4]\tvalid_0's l2: 2.71629\n",
      "[5]\tvalid_0's l2: 2.67201\n",
      "[6]\tvalid_0's l2: 2.63279\n",
      "[7]\tvalid_0's l2: 2.5954\n",
      "[8]\tvalid_0's l2: 2.56321\n",
      "[9]\tvalid_0's l2: 2.5233\n",
      "[10]\tvalid_0's l2: 2.48708\n",
      "[11]\tvalid_0's l2: 2.46275\n",
      "[12]\tvalid_0's l2: 2.43743\n",
      "[13]\tvalid_0's l2: 2.41322\n",
      "[14]\tvalid_0's l2: 2.38992\n",
      "[15]\tvalid_0's l2: 2.37058\n",
      "[16]\tvalid_0's l2: 2.34729\n",
      "[17]\tvalid_0's l2: 2.32335\n",
      "[18]\tvalid_0's l2: 2.30347\n",
      "[19]\tvalid_0's l2: 2.28813\n",
      "[20]\tvalid_0's l2: 2.2722\n",
      "[21]\tvalid_0's l2: 2.2547\n",
      "[22]\tvalid_0's l2: 2.24057\n",
      "[23]\tvalid_0's l2: 2.22825\n",
      "[24]\tvalid_0's l2: 2.21191\n",
      "[25]\tvalid_0's l2: 2.19852\n",
      "[26]\tvalid_0's l2: 2.19304\n",
      "[27]\tvalid_0's l2: 2.18343\n",
      "[28]\tvalid_0's l2: 2.17414\n",
      "[29]\tvalid_0's l2: 2.16821\n",
      "[30]\tvalid_0's l2: 2.16202\n",
      "score LGB = 0.09923619840937313\n",
      "Training Lasso model...\n",
      "score Lasso = 0.11234453415257518\n",
      "Training RandomForest model...\n",
      "score RF = 0.09887804164588575\n",
      "fold = 4\n",
      "Training XGBoost model...\n",
      "score XGB = 0.0998745221216054\n",
      "Training LightGBM model...\n",
      "[1]\tvalid_0's l2: 3.10912\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 3.04793\n",
      "[3]\tvalid_0's l2: 2.99223\n",
      "[4]\tvalid_0's l2: 2.93046\n",
      "[5]\tvalid_0's l2: 2.87492\n",
      "[6]\tvalid_0's l2: 2.81617\n",
      "[7]\tvalid_0's l2: 2.76956\n",
      "[8]\tvalid_0's l2: 2.7279\n",
      "[9]\tvalid_0's l2: 2.68836\n",
      "[10]\tvalid_0's l2: 2.65182\n",
      "[11]\tvalid_0's l2: 2.61486\n",
      "[12]\tvalid_0's l2: 2.57851\n",
      "[13]\tvalid_0's l2: 2.54058\n",
      "[14]\tvalid_0's l2: 2.51151\n",
      "[15]\tvalid_0's l2: 2.48569\n",
      "[16]\tvalid_0's l2: 2.45616\n",
      "[17]\tvalid_0's l2: 2.42707\n",
      "[18]\tvalid_0's l2: 2.39945\n",
      "[19]\tvalid_0's l2: 2.37878\n",
      "[20]\tvalid_0's l2: 2.36452\n",
      "[21]\tvalid_0's l2: 2.34534\n",
      "[22]\tvalid_0's l2: 2.32864\n",
      "[23]\tvalid_0's l2: 2.31207\n",
      "[24]\tvalid_0's l2: 2.29401\n",
      "[25]\tvalid_0's l2: 2.28259\n",
      "[26]\tvalid_0's l2: 2.27371\n",
      "[27]\tvalid_0's l2: 2.26133\n",
      "[28]\tvalid_0's l2: 2.25295\n",
      "[29]\tvalid_0's l2: 2.2415\n",
      "[30]\tvalid_0's l2: 2.23124\n",
      "score LGB = 0.09988271202373337\n",
      "Training Lasso model...\n",
      "score Lasso = 0.11378890492461681\n",
      "Training RandomForest model...\n",
      "score RF = 0.100765523750447\n",
      "fold = 5\n",
      "Training XGBoost model...\n",
      "score XGB = 0.10189133624421098\n",
      "Training LightGBM model...\n",
      "[1]\tvalid_0's l2: 3.15827\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[2]\tvalid_0's l2: 3.09292\n",
      "[3]\tvalid_0's l2: 3.02887\n",
      "[4]\tvalid_0's l2: 2.97938\n",
      "[5]\tvalid_0's l2: 2.93034\n",
      "[6]\tvalid_0's l2: 2.88515\n",
      "[7]\tvalid_0's l2: 2.84527\n",
      "[8]\tvalid_0's l2: 2.81036\n",
      "[9]\tvalid_0's l2: 2.77131\n",
      "[10]\tvalid_0's l2: 2.74039\n",
      "[11]\tvalid_0's l2: 2.71319\n",
      "[12]\tvalid_0's l2: 2.68406\n",
      "[13]\tvalid_0's l2: 2.65513\n",
      "[14]\tvalid_0's l2: 2.63148\n",
      "[15]\tvalid_0's l2: 2.60686\n",
      "[16]\tvalid_0's l2: 2.57744\n",
      "[17]\tvalid_0's l2: 2.56355\n",
      "[18]\tvalid_0's l2: 2.54672\n",
      "[19]\tvalid_0's l2: 2.52479\n",
      "[20]\tvalid_0's l2: 2.50883\n",
      "[21]\tvalid_0's l2: 2.49503\n",
      "[22]\tvalid_0's l2: 2.48129\n",
      "[23]\tvalid_0's l2: 2.45752\n",
      "[24]\tvalid_0's l2: 2.4455\n",
      "[25]\tvalid_0's l2: 2.42647\n",
      "[26]\tvalid_0's l2: 2.41664\n",
      "[27]\tvalid_0's l2: 2.40565\n",
      "[28]\tvalid_0's l2: 2.3965\n",
      "[29]\tvalid_0's l2: 2.39014\n",
      "[30]\tvalid_0's l2: 2.3783\n",
      "score LGB = 0.10397896223821275\n",
      "Training Lasso model...\n",
      "score Lasso = 0.11513434322790428\n",
      "Training RandomForest model...\n",
      "score RF = 0.10264823706886024\n",
      "mean score: 0.1\n"
     ]
    }
   ],
   "source": [
    "scores_list = list()\n",
    "n = 1\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, gamma=0, subsample=0.6,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "lasso = Lasso(alpha = 0.1, random_state = RANDOM_STATE)\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs = 4, random_state = RANDOM_STATE)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "    }\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold = {}'.format(n))\n",
    "    train_X, valid_X = X[train_index], X[test_index]\n",
    "    train_y, valid_y = y[train_index], y[test_index]\n",
    "    \n",
    "    # XGBoost\n",
    "    print('Training XGBoost model...')\n",
    "    xgb_model.fit(train_X, train_y)\n",
    "    preds_xgb = xgb_model.predict(valid_X)\n",
    "    score_xgb = rmsle(valid_y, preds_xgb)\n",
    "    print('score XGB = {}'.format(score_xgb))\n",
    "    \n",
    "    #LightGBM\n",
    "    print('Training LightGBM model...')\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(valid_X, valid_y, reference=lgb_train)\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=30,\n",
    "                    valid_sets=lgb_eval,\n",
    "    early_stopping_rounds=10)\n",
    "    preds_lgb = gbm.predict(valid_X)\n",
    "    score_lgb = rmsle(valid_y, preds_lgb)\n",
    "    print('score LGB = {}'.format(score_lgb))\n",
    "    \n",
    "    #Lasso\n",
    "    print('Training Lasso model...')\n",
    "    lasso.fit(train_X, train_y)\n",
    "    preds_lasso = lasso.predict(valid_X)\n",
    "    score_lasso = rmsle(valid_y, preds_lasso)\n",
    "    print('score Lasso = {}'.format(score_lasso))\n",
    "    \n",
    "    #RandomForest\n",
    "    print('Training RandomForest model...')\n",
    "    rf.fit(train_X, train_y)\n",
    "    preds_rf = rf.predict(valid_X)\n",
    "    score_rf = rmsle(valid_y, preds_rf)\n",
    "    print('score RF = {}'.format(score_rf))\n",
    "    \n",
    "    preds = (preds_xgb*preds_lgb*preds_lasso*preds_rf)**(1/4)\n",
    "    \n",
    "    score = rmsle(valid_y, preds)\n",
    "    scores_list.append(score)\n",
    "    n += 1\n",
    "    \n",
    "print('mean score: {}'.format(round(np.sum(scores_list)/K,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0997"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.sum(scores_list)/K,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions of Models stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stack_predict(X_test):\n",
    "    test_preds_xgb = xgb_model.predict(X_test)\n",
    "    test_preds_gbm = gbm.predict(X_test)\n",
    "    test_preds_lasso = lasso.predict(X_test)\n",
    "    test_preds_xgb = rf.predict(X_test)\n",
    "    \n",
    "    return np.expm1((test_preds_xgb*test_preds_gbm*test_preds_lasso*test_preds_xgb)**(1/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stack_predict_2(X_test):\n",
    "    test_preds_xgb = xgb_model.predict(X_test)\n",
    "    test_preds_gbm = gbm.predict(X_test)\n",
    "    test_preds_lasso = lasso.predict(X_test)\n",
    "    test_preds_xgb = rf.predict(X_test)\n",
    "    \n",
    "    return np.expm1((test_preds_xgb+test_preds_gbm+test_preds_lasso+test_preds_xgb)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    if not os.path.exists('models/'):\n",
    "        os.makedirs('models/')\n",
    "    joblib.dump(model, 'models/{0}.pkl'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(lasso, 'lasso')\n",
    "save_model(gbm, 'lightgbm')\n",
    "save_model(rf, 'randomforest')\n",
    "save_model(xgb_model, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = joblib.load('models/lasso.pkl') \n",
    "gbm = joblib.load('models/lightgbm.pkl') \n",
    "rf = joblib.load('models/randomforest.pkl') \n",
    "xgb_model = joblib.load('models/xgboost.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-71cc4b14d267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mlgb_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m gbm = lgb.train(params,\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mlgb_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "lasso.fit(X, y)\n",
    "rf.fit(X, y)\n",
    "xgb_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 200,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    #\"min_split_gain\":0.2,\n",
    "    \"min_child_weight\":10,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X, y)\n",
    "gbm = lgb.train(lgbm_params,\n",
    "                lgb_train,\n",
    "                num_boost_round=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test = list()\n",
    "preds_test += stack_predict(X[:10]).tolist()\n",
    "preds_test += stack_predict(X[10:20]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6345990.75704731,\n",
       " 1119124.1343001341,\n",
       " 3686354.825470887,\n",
       " 1766782.8797762825,\n",
       " 3817699.604718766,\n",
       " 2101616.641633009,\n",
       " 376826.15027689934,\n",
       " 2143474.7288047536,\n",
       " 1738838.5910107351,\n",
       " 1353520.3048214323,\n",
       " 1839467.0435499107,\n",
       " 4993806.019932196,\n",
       " 833031.8261892154,\n",
       " 3287418.2180998544,\n",
       " 766793.9196172775,\n",
       " 1068313.0446963382,\n",
       " 590956.4784681009,\n",
       " 2676023.746294218,\n",
       " 2155334.31688239,\n",
       " 653293.5514291452]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and predicting TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 53801 aprox row in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del X\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(CS = 1e4):\n",
    "    preds_test = list()\n",
    "    IDs = list()\n",
    "    reader = pd.read_table('data/scaled_test.csv', sep=',', chunksize=CS)\n",
    "    n = 0\n",
    "    for chunk in reader:\n",
    "        IDs += chunk['ID'].tolist()\n",
    "        X_test = chunk.loc[:,chunk.columns != 'ID']\n",
    "        X_test = np.array(chunk.drop(['target','ID'], axis = 1))\n",
    "        preds_test += stack_predict(X_test).tolist()\n",
    "        n += 1\n",
    "    return preds_test, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test, IDs = predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds_test = list()\n",
    "# IDs = list()\n",
    "# reader = pd.read_table('data/scaled_test.csv', sep=',', chunksize=1e4)\n",
    "# n = 0\n",
    "# for chunk in reader:\n",
    "# #     print(chunk)\n",
    "# #     print(len(chunk))\n",
    "#     np.array(train.drop(['target','ID'], axis = 1))\n",
    "#     IDs += chunk['ID'].tolist()\n",
    "#     X_test = chunk.loc[:,chunk.columns != 'ID']\n",
    "#     X_test = np.array(chunk.drop(['target','ID'], axis = 1))\n",
    "#     preds_test += stack_predict(X_test).tolist()\n",
    "#     n += 1\n",
    "#     if n == 2:\n",
    "#         break\n",
    "# print(preds_test, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 49342)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_test), len(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(name, preds_test, IDs):\n",
    "    if not os.path.exists('submissions/'):\n",
    "        os.makedirs('submissions/')\n",
    "    with open('submissions/{}.csv'.format(name), 'w') as f:\n",
    "        n = 0\n",
    "        f.write(\"ID,target\\n\")\n",
    "        for _ in range(len(preds_test)):\n",
    "            f.write(\"%s,%s\\n\" % (IDs[n], preds_test[n]))\n",
    "            n += 1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit('first', preds_test, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit('second', preds_test, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit('third', preds_test, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del preds_test\n",
    "del IDs\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
